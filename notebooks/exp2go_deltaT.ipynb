{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exp2go_42_deltaT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF7E0eQoJt3W"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5E5ueFs5QSZR"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cupy as cp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSFnSXz6PhOm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "779d5dea-72da-406f-edde-15e5efc2455c"
      },
      "source": [
        "!git clone https://github.com/sinc-lab/exp2GO.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'exp2GO'...\n",
            "remote: Enumerating objects: 211, done.\u001b[K\n",
            "remote: Counting objects: 100% (211/211), done.\u001b[K\n",
            "remote: Compressing objects: 100% (198/198), done.\u001b[K\n",
            "remote: Total 211 (delta 77), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (211/211), 40.17 MiB | 15.48 MiB/s, done.\n",
            "Resolving deltas: 100% (77/77), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCU8achmRTeO"
      },
      "source": [
        "path = 'exp2GO/data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tr_p4XpwiQV"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRfXwvc2a2Tn"
      },
      "source": [
        "species = 'ara' # ara dicty yeast\n",
        "\n",
        "if species=='ara':\n",
        "  gafnr_1 = '131'\n",
        "  gafnr00 = '138'\n",
        "else:\n",
        "  gafnr_1 = '59'\n",
        "  gafnr00 = '66'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BvMY1D-ileh"
      },
      "source": [
        "## Annotations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8Ws1lDa9pps"
      },
      "source": [
        "onto = 'BP'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMmmuA0rKhLf"
      },
      "source": [
        "ancestorsT_1 = pd.read_csv(path + species + '_terms_gaf'+ gafnr_1 +\n",
        "                           '_obo2016-06-01_' + onto + '_with_expr_EXP_FILTERED_terms_anc.csv',\n",
        "                           header=None, index_col=0)\n",
        "\n",
        "#ancestorsT_1 = ancestorsT_1.dropna(axis=0, how='all') # DROP NA VALUES\n",
        "ancestorsT_1.fillna('',inplace=True)\n",
        "ancestorsT_1.index = [x.upper() for x in ancestorsT_1.index]\n",
        "\n",
        "labelsT_1 = np.unique(ancestorsT_1.to_numpy().ravel())\n",
        "labelsT_1 = labelsT_1[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0PtbYIHLSPO"
      },
      "source": [
        "ancestorsT0 = pd.read_csv(path + species + '_terms_gaf' + gafnr00 +\n",
        "                          '_obo2016-06-01_' + onto + '_with_expr_EXP_FILTERED_terms_anc.csv',\n",
        "                          header=None, index_col=0)\n",
        "\n",
        "ancestorsT0 = ancestorsT0.dropna(axis=0, how='all') # drop NA values \n",
        "ancestorsT0.fillna('',inplace=True)\n",
        "ancestorsT0.index = [x.upper() for x in ancestorsT0.index]\n",
        "\n",
        "labelsT0 = np.unique(ancestorsT0.to_numpy().ravel())\n",
        "labelsT0 = labelsT0[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1joha1qwpIG"
      },
      "source": [
        "## Distance matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFa_gZYrAVU4"
      },
      "source": [
        "De = pd.read_csv(path + species + '_expression_dist_cosine.csv.zip', header=0, index_col=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U26vXhLlwVwS"
      },
      "source": [
        "Dg = pd.read_csv(path + species + '_semantic_dist_' + onto + '_rel_min_exp_FILTERED_terms.csv.zip',\n",
        "                 header=0, index_col=0)\n",
        "Dg.index = Dg.index.str.upper()\n",
        "Dg.columns = Dg.columns.str.upper()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62EbcbUGsIgf"
      },
      "source": [
        "### Filter with T0 genes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfUitPh0pRuy"
      },
      "source": [
        "genes = list(ancestorsT0.index)\n",
        "#print(len(genes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs7nTi6gsSHp"
      },
      "source": [
        "#Filter expression matrix according to TO-GO matrix\n",
        "De = De.filter(items=genes, axis=0)\n",
        "De = De.filter(items=genes, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0Ygfn1LipzE"
      },
      "source": [
        "Dg = Dg.filter(items=genes, axis=0)\n",
        "Dg = Dg.filter(items=genes, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8Xv-KWshhik"
      },
      "source": [
        "# Filter T-1 genes\n",
        "ancestorsT_1 = ancestorsT_1.filter(items=genes, axis=0) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RlP8Ang0Ofl"
      },
      "source": [
        "## Detect LKs and NKs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FiUPG3yvJn8"
      },
      "source": [
        "def countLKNCNK(prots_Tini, prots_Tend):\n",
        "  \n",
        "  allprots = np.union1d(prots_Tini.index,prots_Tend.index)\n",
        "  LK = []\n",
        "  NK = []\n",
        "\n",
        "  Nlk, Nnc, Nnk = 0, 0, 0\n",
        "  for prot in allprots:\n",
        "    terms_1 = set(prots_Tini.loc[prot]) - set([''])\n",
        "    terms00 = set(prots_Tend.loc[prot]) - set([''])\n",
        "    if terms_1 == terms00:\n",
        "      Nnc += 1\n",
        "    elif len(terms_1) == 0:\n",
        "      Nnk += 1\n",
        "      NK.append(prot)\n",
        "    elif terms_1 < terms00:\n",
        "      Nlk += 1\n",
        "      LK.append(prot)\n",
        "    else:\n",
        "      # (implicit NC)\n",
        "      if len(terms_1) == len(terms00):\n",
        "        print('Warning: protein {} has same number of terms in T-1 than T0, BUT changed!'.format(prot))\n",
        "      else:\n",
        "        print('Warning: protein {} has more terms in T-1 ({}) than T0 ({})'.format(prot,len(terms_1),len(terms00)))\n",
        "\n",
        "  return Nlk, Nnc, Nnk, LK, NK"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAyzb3s4OUE6"
      },
      "source": [
        "Nlk, Nnc, Nnk, LK, NK = countLKNCNK(ancestorsT_1, ancestorsT0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ms8fdr570x0H"
      },
      "source": [
        "## Convert GO-terms string to numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzUF4QsKpLi2"
      },
      "source": [
        "alllabels = list(set(labelsT_1).intersection(set(labelsT0)))\n",
        "labels = np.zeros((len(alllabels),) , dtype=np.uint64)\n",
        "for i, lab in enumerate(alllabels):\n",
        "  labels[i]=int(lab[3:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDCuebLz4BMc"
      },
      "source": [
        "# change GO terms to numbers only in ancestors\n",
        "def ancestors2num(anc_str):\n",
        "  ancestors = pd.DataFrame()\n",
        "  for gen in anc_str:\n",
        "    labs = []\n",
        "    for i in range(len(anc_str[gen])):\n",
        "      num=anc_str[gen][i][3:]\n",
        "      if num != '':\n",
        "        labs.append(int(num))\n",
        "      else:\n",
        "        labs.append(0)\n",
        "    ancestors[gen] = labs\n",
        "  ancestors.set_index(anc_str.index, inplace=True)\n",
        "  return ancestors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WdIPQq_4hQr"
      },
      "source": [
        "ancT_1 = ancestors2num(ancestorsT_1)\n",
        "ancT0 = ancestors2num(ancestorsT0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGjKuFwoeRWp"
      },
      "source": [
        "# NNMF d_GO reconstruction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOHGVq6vi_Wa"
      },
      "source": [
        "#### Auxiliary functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI6DjxWileXR"
      },
      "source": [
        "def send2back(d,idx):\n",
        "  # sent to back these cols and rows in d\n",
        "\n",
        "  Nd = d.shape[0]\n",
        "  Ns = idx.shape[0]\n",
        "\n",
        "  idxinv = np.setdiff1d(np.arange(0,Nd),idx)\n",
        "  idxinvidx = np.concatenate((idxinv, idx)) # new order\n",
        "  \n",
        "  dx = np.zeros(d.shape)\n",
        "\n",
        "  dx[np.ix_(range(Nd-Ns),range(Nd-Ns))] = d[np.ix_(idxinv,idxinv)] # compacted left-up submatrix\n",
        "  dx[np.ix_(range(Nd-Ns,Nd),range(Nd))] = d[np.ix_(idx,idxinvidx)] # last rows\n",
        "  dx[np.ix_(range(Nd),range(Nd-Ns,Nd))] = d[np.ix_(idxinvidx,idx)] # last cols\n",
        "\n",
        "  return dx\n",
        "\n",
        "def zeroback(d, Ns):\n",
        "\n",
        "  Nd = d.shape[0]\n",
        "  d[np.ix_(range(Nd-Ns,Nd),range(Nd))] = 0;\n",
        "  d[np.ix_(range(Nd),range(Nd-Ns,Nd))] = 0;\n",
        "\n",
        "  return d\n",
        "\n",
        "def return2future(db, idx):\n",
        "  # restore last of db ows/cols to the idx positions\n",
        "\n",
        "  Nd = db.shape[0]\n",
        "  Ns = idx.shape[0]\n",
        "\n",
        "  idxinv = np.setdiff1d(np.arange(0,Nd),idx)\n",
        "  idxinvidx = np.concatenate((idxinv, idx)) # new order\n",
        "  \n",
        "  dx = np.zeros(db.shape)\n",
        "\n",
        "  dx[np.ix_(idxinv,idxinv)] = db[np.ix_(range(Nd-Ns),range(Nd-Ns))] # expand rows and cols\n",
        "  dx[np.ix_(idx,idxinvidx)] = db[np.ix_(range(Nd-Ns,Nd),range(Nd))] # return last rows\n",
        "  dx[np.ix_(idxinvidx,idx)] = db[np.ix_(range(Nd),range(Nd-Ns,Nd))] # return last cols\n",
        "\n",
        "  return dx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUF1CQ-Wi1z2"
      },
      "source": [
        "#### NNMF CuPy version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5IsHaBVDM03"
      },
      "source": [
        "def ssnmf_cp(De,Dg,Nc,lmbd,k,max_iter):\n",
        "  \n",
        "  (m,n) = De.shape\n",
        "\n",
        "  cp.random.seed(seed=333) \n",
        "  A = cp.random.rand(m,k)\n",
        "  S1 = cp.random.rand(k,n)\n",
        "  S2 = cp.random.rand(k,n)\n",
        "\n",
        "  p = m-Nc\n",
        "  W = cp.zeros((m,n))\n",
        "  W[cp.ix_(range(Nc),range(Nc))] = 1\n",
        "\n",
        "  # learinng the base\n",
        "  e1ant = 1000\n",
        "  e2ant = 1000\n",
        "  cont = 0\n",
        "  maxcont = 10\n",
        "  tol = 0.001\n",
        "\n",
        "  l = 0\n",
        "  cont = 0\n",
        "  while (l<max_iter) and (cont<maxcont):\n",
        "    A = A *( De @S1.T+  lmbd*(W *Dg)@S2.T)/((A@S1)@S1.T+  lmbd*(W *(A@S2))@S2.T+0.0000001)\n",
        "    for u in range(k):\n",
        "      A[:,u] = A[:,u]/cp.linalg.norm(A[:,u])\n",
        "    S1 = S1 * ((A.T@De)/(A.T@(A@S1)+0.0000001))\n",
        "    S2 = S2 * ((A.T@(W*Dg))/(A.T@(W*(A@S2))+0.0000001))\n",
        "    err1 = cp.linalg.norm(De-A@S1,'fro')\n",
        "    err2 = cp.linalg.norm(W*(Dg-A@S2),'fro')\n",
        "    if (2-err1/e1ant-err2/e2ant)<tol:\n",
        "      cont = cont+1\n",
        "    else:\n",
        "      cont = 0\n",
        "    e1ant = err1\n",
        "    e2ant = err2\n",
        "    l = l+1\n",
        "    #if l%100 == 0: print('l1: ',l)\n",
        "    #if l==1: time0 = time.time()\n",
        "    #if l==11: print('l1 10 time', time.time()-time0)\n",
        "\n",
        "  miter = l        \n",
        "\n",
        "  # full Dg estimation\n",
        "  Dr1 = A@S2\n",
        "  Dr1[cp.ix_(range(Nc),range(Nc,len(Dr1)))] =0\n",
        "  Dr2 = ((1-W)*Dr1).T + Dr1\n",
        "\n",
        "  # weigths redefinition\n",
        "  W = cp.ones((m,n))\n",
        "  W[cp.ix_(range(Nc,m),range(Nc,n))] = 0\n",
        "\n",
        "  S2[cp.ix_(range(k),range(Nc,n))] = cp.ones((k,p)); #rand(k,p)\n",
        "  eant = 1000\n",
        "  cont = 0\n",
        "  maxcont = 10\n",
        "  tol = 0.00001\n",
        "\n",
        "  l = 0\n",
        "  cont = 0\n",
        "  while (l<max_iter) and (cont<maxcont):\n",
        "    S2 = S2*((A.T@(W*Dr2))/(A.T@(W*(A@S2))+0.0000001))\n",
        "    err=cp.linalg.norm(W*(Dr2-A@S2),'fro')\n",
        "    if abs(1-err/eant)<tol:\n",
        "      cont = cont+1\n",
        "    else:\n",
        "      cont = 0\n",
        "    eant=err\n",
        "    l = l+1\n",
        "    #if l%100 == 0: print('l2: ',l)\n",
        "\n",
        "  aux = A@S2\n",
        "  aux1 = aux[Nc:,Nc:]\n",
        "  aux1 = (aux1.T+aux1)/2\n",
        "\n",
        "  #Dr3 = Dr2\n",
        "  Dr2[cp.ix_(range(Nc,len(Dr2)),range(Nc,len(Dr2)))] = aux1\n",
        "  Dr2 = cp.minimum(Dr2,cp.max(Dg)*cp.ones(Dr2.shape))\n",
        "\n",
        "  return Dr2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "811w1Le2i56J"
      },
      "source": [
        "#### NNMF numpy version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vd8KXkr4xYY"
      },
      "source": [
        "def ssnmf(De,Dg,Nc,lmbd,k,max_iter):\n",
        "\n",
        "  (m,n) = De.shape\n",
        "  np.random.seed(seed=333)\n",
        "  A = np.random.rand(m,k)\n",
        "  S1 = np.random.rand(k,n)\n",
        "  S2 = np.random.rand(k,n)\n",
        "\n",
        "  p = m-Nc\n",
        "  W = np.zeros((m,n))\n",
        "  W[np.ix_(range(Nc),range(Nc))] = 1\n",
        "\n",
        "  # learning the base\n",
        "  e1ant = 1000\n",
        "  e2ant = 1000\n",
        "  cont = 0\n",
        "  maxcont = 10\n",
        "  tol = 0.0001\n",
        "\n",
        "  l = 0\n",
        "  cont = 0\n",
        "  while (l<max_iter) and (cont<maxcont):\n",
        "    A = A *( De @S1.T+  lmbd*(W *Dg)@S2.T)/((A@S1)@S1.T+  lmbd*(W *(A@S2))@S2.T+0.0000001)\n",
        "    for u in range(k):\n",
        "      A[:,u] = A[:,u]/np.linalg.norm(A[:,u])\n",
        "    S1 = S1 * ((A.T@De)/(A.T@(A@S1)+0.0000001))\n",
        "    S2 = S2 * ((A.T@(W*Dg))/(A.T@(W*(A@S2))+0.0000001))\n",
        "    err1 = np.linalg.norm(De-A@S1,'fro')\n",
        "    err2 = np.linalg.norm(W*(Dg-A@S2),'fro')\n",
        "    if (2-err1/e1ant-err2/e2ant)<tol:\n",
        "      cont = cont+1\n",
        "    else:\n",
        "      cont = 0\n",
        "    e1ant = err1\n",
        "    e2ant = err2\n",
        "    l = l+1\n",
        "    if l%100 == 0: print('l1: ',l)\n",
        "    if l==1: time0 = time.time()\n",
        "    if l==11: print('l1 10 time', time.time()-time0)\n",
        "\n",
        "  miter = l        \n",
        " \n",
        "  # full Dg estimation\n",
        "  Dr1 = A@S2\n",
        " \n",
        "  Dr1[cp.ix_(range(Nc),range(Nc,len(Dr1)))] =0\n",
        "  Dr2 = ((1-W)*Dr1).T + Dr1\n",
        "\n",
        "  # weigths redefinition\n",
        "  W = np.ones((m,n))\n",
        "  W[np.ix_(range(Nc,m),range(Nc,n))] = 0\n",
        "\n",
        "  S2[np.ix_(range(k),range(Nc,n))] = np.ones((k,p)); #rand(k,p)\n",
        "  eant = 1000\n",
        "  cont = 0\n",
        "  maxcont = 10\n",
        "  tol = 0.00001\n",
        "\n",
        "  l = 0\n",
        "  cont = 0\n",
        "  while (l<max_iter) and (cont<maxcont):\n",
        "    S2 = S2*((A.T@(W*Dr2))/(A.T@(W*(A@S2))+0.0000001))\n",
        "    err=np.linalg.norm(W*(Dr2-A@S2),'fro')\n",
        "    if abs(1-err/eant)<tol:\n",
        "      cont = cont+1\n",
        "    else:\n",
        "      cont = 0\n",
        "    eant=err\n",
        "    l = l+1\n",
        "    if l%100 == 0: print('l2: ',l)\n",
        "\n",
        "  aux = A@S2\n",
        "  aux1 = aux[Nc:,Nc:]\n",
        "  aux1 = (aux1.T+aux1)/2\n",
        "\n",
        "  #Dr3 = Dr2\n",
        "  Dr2[np.ix_(range(Nc,len(Dr2)),range(Nc,len(Dr2)))] = aux1\n",
        "  Dr2 = np.minimum(Dr2,np.max(Dg)*np.ones(Dr2.shape))\n",
        "\n",
        "  return Dr2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qg0Q3X-0ZzOt"
      },
      "source": [
        "#### NNMF-GO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uszcNSnyfR01"
      },
      "source": [
        "def nnmfgo(d_expr, d_GO, idx_to_rec, lmbd, dim, max_iter):\n",
        "\n",
        "  # Format GO distance matrix (back and blank genes to annotate)\n",
        "  dg = send2back(d_GO,idx_to_rec)\n",
        "  dg = zeroback(dg,len(idx_to_rec))\n",
        "\n",
        "  # Format expression distance matrix (back genes to annotate)\n",
        "  de = send2back(d_expr,idx_to_rec)\n",
        "\n",
        "  # NNMF\n",
        "  num_genes_annotated = d_expr.shape[0]-len(idx_to_rec)\n",
        "\n",
        "  # without cupy: 392 s for 10 iterations (aprox 10 h for 400 l1 + 500 l2)\n",
        "  #rec = ssnmf(d_expr,d_GO,num_genes_annotated,lmbd,dim,max_iter)\n",
        "  \n",
        "  # with cupy: 11 s for 10 iterations (aprox 18 min for 400 l1 + 500 l2)\n",
        "  d_GO_cp = cp.array(dg)  \n",
        "  d_expr_cp = cp.array(de)\n",
        "  rec_cp = ssnmf_cp(d_expr_cp,d_GO_cp,num_genes_annotated,lmbd,dim,max_iter)\n",
        "  rec = cp.asnumpy(rec_cp)\n",
        "  #rec = cp.asnumpy(d_GO_cp)\n",
        "\n",
        "  # Restore the original order in the distance matrix\n",
        "  d_GO_rec = return2future(rec,idx_to_rec)\n",
        "\n",
        "  return d_GO_rec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Q3Kc8YTj_mF"
      },
      "source": [
        "# Bayesian inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbUFRXtp2a4M"
      },
      "source": [
        "def bayesprobs(d,idxB,labelsAwB,ancestors,pexp):\n",
        "  # ancestors: GO terms for each known gene\n",
        "\n",
        "  idxA = np.setdiff1d(np.arange(0,len(d)),idxB) # annotated genes\n",
        "  \n",
        "  weights = np.zeros((len(idxB),len(labelsAwB))) # % ~> likelihood p(gene|label)\n",
        "  countAB = np.zeros((len(idxB),len(labelsAwB))) # % ~> prior p(label)\n",
        "\n",
        "  for genB in range(len(idxB)):\n",
        "    col = idxB[genB]\n",
        "    dnorm_col = d[:,col] \n",
        "    dnorm_col = (dnorm_col-np.min(dnorm_col))/(np.max(dnorm_col)-np.min(dnorm_col))\n",
        "    for genA in range(len(idxA)):\n",
        "      labsA = ancestors.iloc[idxA[genA],:].dropna().to_numpy()\n",
        "      labsA = np.setxor1d([0],labsA)\n",
        "      row = idxA[genA]\n",
        "      d_gen=d[row,col]\n",
        "      for t in range(len(labsA)):\n",
        "        idxLab = np.where(labelsAwB == labsA[t])\n",
        "        weights[genB,idxLab] = weights[genB,idxLab]+(2/(1+d_gen)-1)**pexp \n",
        "        countAB[genB,idxLab] = countAB[genB,idxLab]+1\n",
        "\n",
        "  return (weights, countAB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO-6IEG0LkuO"
      },
      "source": [
        "def bayesinf(genB,p,cumpcut,labelsAwB):\n",
        "\n",
        "  prob = p[genB,:]\n",
        "  prob = prob/np.sum(prob)\n",
        "  ind = np.argsort(prob)\n",
        "  indd = ind[::-1] # descendent sort\n",
        "  cum = np.cumsum(prob[indd])\n",
        "  pp = np.argmax(cum>cumpcut)\n",
        "  inB = labelsAwB[indd[:pp+1]]\n",
        "  \n",
        "  return (inB, indd, cum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSJMFnCCtYSg"
      },
      "source": [
        "# separated for otimization\n",
        "def bayesinf_nocut(genB,p):\n",
        "\n",
        "  prob = p[genB,:]\n",
        "  prob = prob/np.sum(prob)\n",
        "  ind = np.argsort(prob)\n",
        "  indd = ind[::-1] # descendent sort\n",
        "  cum = np.cumsum(prob[indd])\n",
        "  \n",
        "  return indd, cum\n",
        "\n",
        "def bayesinf_justcut(cum, cumpcut, indd, labelsAwB):\n",
        "\n",
        "  pp = np.argmax(cum>cumpcut)\n",
        "  inB = labelsAwB[indd[:pp+1]]\n",
        "  \n",
        "  return inB\n",
        "\n",
        "def simple_cut(score, cumpcut, labels):\n",
        "\n",
        "  pp = np.argmax(score>cumpcut)\n",
        "  inB = labels[pp]\n",
        "  \n",
        "  return inB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAzL48VmLr9y"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSc3OXahLwsO"
      },
      "source": [
        "#### Performance measures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvdTFIralN5P"
      },
      "source": [
        "def spf1(refP,refN,predP,labels,remove_labels=[]):\n",
        "  if len(remove_labels)>0:\n",
        "    refP = np.setdiff1d(refP,remove_labels)\n",
        "    predP = np.setdiff1d(predP,remove_labels)\n",
        "\n",
        "  predN = np.setdiff1d(labels,predP)\n",
        "  TP = len(np.intersect1d(refP,predP))\n",
        "  TN = len(np.intersect1d(refN,predN))\n",
        "  FP = len(np.intersect1d(predP,refN))\n",
        "  FN = len(np.intersect1d(predN,refP))\n",
        "  sens = TP/(TP+FN)\n",
        "  if TP+FP>0: prec = TP/(TP+FP)\n",
        "  else: prec = 0\n",
        "  if sens+prec>0: F1 = 2*sens*prec/(sens+prec)\n",
        "  else: F1 = 0\n",
        "  return (TP, TN, FP, FN, sens, prec, F1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgmMdnr9Zu2m"
      },
      "source": [
        "### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5yWh_BRPqXM"
      },
      "source": [
        "lmbd = 0.001      #@param {type:\"slider\", min:0, max:200000, step:0.05}\n",
        "dim = 80        #@param {type:\"slider\", min:10, max:2000, step:10}\n",
        "pexp = 6        #@param {type:\"slider\", min:1, max:15, step:1}\n",
        "max_iter = 500  #@param {type:\"slider\", min:1, max:5000, step:100}\n",
        "tol = 0.001     #@param {type:\"slider\", min:0, max:1, step:0.001}\n",
        "\n",
        "gamma = 1.0     #param {type:\"slider\", min:0, max:1, step:0.05}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGKvZP2SphL5"
      },
      "source": [
        "Ngenes = Dg.shape[0]\n",
        "Nlabels = len(labels)\n",
        "\n",
        "d_expr = De.to_numpy()\n",
        "d_GO = Dg.to_numpy()    # TO-DO clear copies\n",
        "\n",
        "indx_to_predictLK = np.where(De.index.isin(LK))\n",
        "indx_to_predictNK = np.where(De.index.isin(NK))\n",
        "indx_to_predict = np.concatenate((indx_to_predictLK[0], indx_to_predictNK[0]))\n",
        "indx_unknown = indx_to_predictNK[0]\n",
        "\n",
        "d_GO_rec = nnmfgo(d_expr, d_GO, indx_unknown, lmbd, dim, max_iter)\n",
        "d_GO_final = d_GO_rec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfyHfYoq8X5v"
      },
      "source": [
        "#d_GO_final = Dg.fillna(2.0).to_numpy() # <<< oracle\n",
        "\n",
        "(weights, countAB) = bayesprobs(d_GO_final,indx_to_predict,labels,ancT_1,pexp)\n",
        "p = np.multiply(weights,countAB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5hKZcIOpy1A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e4f9ce9-cef2-4440-ab42-a0ab5f02519a"
      },
      "source": [
        "Ngenes_to_predict = len(indx_to_predict)\n",
        "Max_labs_x_gen = len(ancT0.iloc[0,:].dropna().values)\n",
        "\n",
        "indord = np.zeros((Ngenes_to_predict, Nlabels), dtype=np.uint32)\n",
        "cum =  np.zeros((Ngenes_to_predict, Nlabels))\n",
        "refP = np.zeros((Ngenes_to_predict, Max_labs_x_gen), dtype=np.uint32)\n",
        "refN = np.setdiff1d(labels,refP)\n",
        "remove_labels = np.zeros_like(refP)\n",
        "\n",
        "for k, igenloo in enumerate(indx_to_predict):\n",
        "  indord[k,:], cum[k,:] = bayesinf_nocut(k, p)\n",
        "  refP[k,:] = ancT0.iloc[igenloo,:].dropna().values\n",
        "  remove_labels[k,:] = ancT_1.iloc[igenloo,:].dropna().values\n",
        "\n",
        "Nth = 100\n",
        "cum_ths = np.linspace(0.0+1.0/Nth, 1.0, num=100)\n",
        "F1th = np.zeros((Nth,))\n",
        "F1 = np.zeros((len(cum_ths),Ngenes_to_predict))\n",
        "for ith, ccut in enumerate(cum_ths):\n",
        "  for k in range(Ngenes_to_predict):\n",
        "    labelsB_genB = bayesinf_justcut(cum[k,:], ccut, indord[k,:], labels)\n",
        "    refN = np.setdiff1d(labels, refP[k, :]) \n",
        "    _, _, _, _, _, _, F1[ith,k] = spf1(refP[k,:],refN,labelsB_genB,labels)\n",
        "    F1th[ith] += F1[ith,k]\n",
        "  F1th[ith] = F1th[ith]/len(indx_to_predict)\n",
        "\n",
        "print(F1th)\n",
        "print('F1max:', max(F1th))\n",
        "print('pcut: ', cum_ths[np.argmax(F1th)])\n",
        "\n",
        "print(np.mean(F1[np.argmax(F1th),:]))\n",
        "print(np.std(F1[np.argmax(F1th),:]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.12197825 0.12197825 0.12197825 0.12197825 0.12197825 0.12197825\n",
            " 0.12197825 0.12197825 0.12197825 0.12197825 0.12197825 0.1217173\n",
            " 0.13682797 0.140661   0.15104435 0.16254553 0.16553356 0.16668333\n",
            " 0.17383142 0.17359512 0.18153813 0.18081957 0.18431449 0.19147246\n",
            " 0.20122465 0.21081155 0.21579718 0.2168627  0.22223792 0.2283302\n",
            " 0.23299742 0.24338843 0.24709127 0.24494391 0.2541464  0.2586537\n",
            " 0.25772164 0.25927102 0.25994944 0.2585327  0.26293738 0.27030019\n",
            " 0.27414439 0.27378483 0.27106833 0.27280919 0.2777331  0.27809027\n",
            " 0.28252855 0.2888146  0.28927063 0.29316619 0.30360699 0.30649751\n",
            " 0.31127957 0.31676411 0.32081714 0.33046901 0.33211645 0.33943809\n",
            " 0.34453285 0.34790913 0.34719178 0.35058897 0.35379901 0.35695591\n",
            " 0.35461193 0.35150188 0.35474249 0.352904   0.35347347 0.35654594\n",
            " 0.35903089 0.36723297 0.366796   0.36732559 0.36792784 0.37303478\n",
            " 0.37211577 0.37424573 0.37043337 0.3674981  0.36700496 0.36683395\n",
            " 0.36598753 0.36292789 0.35720537 0.35167131 0.34557663 0.33636699\n",
            " 0.33101563 0.32447914 0.31903786 0.31637115 0.30461075 0.28848646\n",
            " 0.26923025 0.24683196 0.21763142 0.10131093]\n",
            "F1max: 0.3742457340127421\n",
            "pcut:  0.8\n",
            "0.3742457340127421\n",
            "0.16481316296437465\n"
          ]
        }
      ]
    }
  ]
}